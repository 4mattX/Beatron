# ğŸ¶ Beatron ğŸ¶
ğŸµ **Open-Source - Decoder only GPT model to generate MIDI music!** ğŸµ
&nbsp;  
&nbsp;  
ğŸ‰ Welcome to Beatron! ğŸ‰ Dive deep into the power of GPT-like architectures for MIDI music generation. Everything you need is neatly packed within a Jupyter notebook for a quick start.
&nbsp;  

âœ¨ _Quick Highlight:_ This project is all about MIDI music generation with GPT-like architectures. Explore the code, which is richly documented, and get started with just one Jupyter notebook. Modify to your heart's content!
&nbsp;  
&nbsp;  
### ğŸ™ Shoutout To...
- **kvnsoufal**'s MidiTransformer ğŸ¼
  - ğŸ“˜ [Implementation Here](https://github.com/kvsnoufal/MidiTransformer) 
  - ğŸ“– [Medium Article](https://medium.com/mlearning-ai/generating-music-with-gpt-b0f4ab738b58)
&nbsp;  
- The [**BEST GPT Youtube walkthrough**](https://www.youtube.com/watch?v=kCc8FmEb1nY&ab_channel=AndrejKarpathy) by Andrej Karpathy's ğŸ“º
&nbsp;  
&nbsp;  
## ğŸ“˜ Table of Contents
- [ğŸš€ Getting Started](#getting-started)
  - [ğŸ” Important to know](#important-to-know)
  - [ğŸ›  Requirements](#requirements)
  - [ğŸ—‚ File Structure](#file-structure)
- [ğŸ‹ Training the Model](#training-the-model)
- [ğŸ”¬ Loading and Running Tests](#loading-and-running-tests) 
&nbsp;  
## ğŸš€ Getting Started
### ğŸ” Important to know!
- ğŸ““ Built for notebook environments: Jupyter, Databricks, and Google-Colab!
- ğŸµ MIDI data encodings are thanks to [MidiTok](https://miditok.readthedocs.io/en/latest/index.html). 
  - ğŸ¹ Generate your own dataset with the [RemiPlus](https://miditok.readthedocs.io/en/latest/tokenizations.html#remiplus) tokenizer.
&nbsp;  
### ğŸ›  Requirements
- ğŸ¹ MidiTok (MIDI file tokenization)
- ğŸ§  PyTorch (The brain behind model creation, training, and inference)
- ğŸ“Š Pandas (For data manipulation)
- ğŸ”¢ NumPy (matrices and stuff)
&nbsp;  
#### Don't forget to... ğŸ“¦:
  ```pip install MidiTok```
&nbsp;  
### ğŸ—‚ File Structure

Navigating the repo is as easy as reading sheet music! ğŸµ
- `output/`: ğŸ“ Your saved outputs (trained model checkpoints).
- `data_plots/`: ğŸ“Š Visual charts (training-related plots).
- `encoding/`: ğŸ”¢ Encoded midi tracks.
- `preload/`: ğŸš€ Pre-tuned data structures to speed up dataset loading time.
- `songs/`: ğŸ¶ Freshly composed MIDI songs.
- `logs/`: ğŸ“œ log files of the training.
&nbsp;  
&nbsp;  
## ğŸ‹ Training the Model
&nbsp;  
1ï¸âƒ£ Get things rocking with the `train` function:
   - Orchestrates the training process: from logging, data loading to the grand performance of training a Transformer model.
   - Yourmodel checkpoints are safely stored in the `output/` directory every evaluation interval.  
   
2ï¸âƒ£ Watch your model learn with the `plot_and_save` function:
   - Visual feedback (loss plots) will be stored in the `data_plots/` directory as the model learns.  
   
3ï¸âƒ£ Record training details with the `save_training_info` function:
   - Detailed logs and parameters are saved in the `data_plots/` as text documents for your reference.
&nbsp;   
&nbsp;  
## ğŸ”¬ Loading and Running Tests
&nbsp;  
1ï¸âƒ£ Load up a trained model with the `load_model` function:
   - Just point it to your chosen trained model checkpoint in the `output/` directory.  
   
2ï¸âƒ£ Compose with the AI overlords, generate MIDI songs using the testing loop:
   - Dile things in with an initial MIDI sequence from the `encoding/` directory.
   - Your fresh generated MIDI songs are saved in the `songs/` directory.
   
&nbsp;  
ğŸ» _Final note:_ Tweak the constants and parameters (like `VOCAB_SIZE`, `EMBED_DIM`, etc.) to your own taste. ğŸ¼
&nbsp;  
