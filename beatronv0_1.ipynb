{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jygi-oRGOWNC"
      },
      "source": [
        "# **Install Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8bC5SJ5ORZQ",
        "outputId": "16d46298-accc-4342-9166-72b92b49899f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting miditok\n",
            "  Downloading miditok-2.1.5-py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.19 in /usr/local/lib/python3.10/dist-packages (from miditok) (1.23.5)\n",
            "Collecting miditoolkit>=0.1.16 (from miditok)\n",
            "  Downloading miditoolkit-0.1.16-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from miditok) (4.66.1)\n",
            "Collecting tokenizers>=0.13.0 (from miditok)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from miditok) (1.11.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from miditok) (3.7.1)\n",
            "Collecting mido>=1.1.16 (from miditoolkit>=0.1.16->miditok)\n",
            "  Downloading mido-1.3.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.17,>=0.16.4 (from tokenizers>=0.13.0->miditok)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->miditok) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->miditok) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.0->miditok) (2023.7.22)\n",
            "Installing collected packages: mido, miditoolkit, huggingface_hub, tokenizers, miditok\n",
            "Successfully installed huggingface_hub-0.16.4 miditok-2.1.5 miditoolkit-0.1.16 mido-1.3.0 tokenizers-0.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install miditok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B5ITSJzOetQ"
      },
      "source": [
        "# **Import Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwmWh0KPNvkb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from miditok import REMIPlus\n",
        "from miditok.utils import get_midi_programs\n",
        "from miditoolkit import MidiFile\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display, HTML\n",
        "from IPython.core import display as ipydisplay\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import logging\n",
        "import pickle\n",
        "import datetime\n",
        "import json\n",
        "import gc\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU0BIBEbjvrO",
        "tags": []
      },
      "source": [
        "# **Utils**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Function**: `train_one_epoch`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Trains the model for one epoch and optionally performs evaluation at specified intervals. Keeps track of training and validation losses and saves model checkpoints.\n",
        "\n",
        "**Parameters**:\n",
        "- `model` (nn.Module): The model to be trained.\n",
        "- `optimizer` (Optimizer): Optimizer for updating model weights.\n",
        "- `dataloader` (DataLoader): DataLoader object for training data.\n",
        "- `device` (torch.device): Device to move data to (e.g., cuda, cpu).\n",
        "- `epoch` (int): Current training epoch.\n",
        "- `parameters` (dict): Additional parameters like learning rate, etc.\n",
        "- `eval_interval` (int): Interval at which to perform evaluation and save model checkpoints.\n",
        "- `eval_dataloader` (DataLoader, optional): DataLoader object for evaluation data.\n",
        "\n",
        "**Returns**:\n",
        "- `float`: The average loss for the epoch."
      ],
      "metadata": {
        "id": "W_UetB8xYmUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, dataloader, device, epoch, parameters, eval_interval, eval_dataloader=None):\n",
        "    model.train()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    for step, data in bar:\n",
        "        x = data['x'].to(device)\n",
        "        y = data['y'].to(device)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        logits,loss = model.forward(x,y)\n",
        "\n",
        "        if loss.numel() > 1:\n",
        "            loss = loss.mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n",
        "        if step % eval_interval == 0:\n",
        "            train_losses.append(epoch_loss)\n",
        "            val_losses.append(epoch_loss)\n",
        "\n",
        "            plot_and_save(step, train_losses, val_losses, FILE_NAME, parameters, EMBED_DIM, TRANSFORMER_HEADS, TRANSFORMER_LAYERS)\n",
        "\n",
        "            # Save the model after evaluation\n",
        "            model_save_name = f\"{FILE_NAME}_e_{epoch}_s_{step}.pt\"\n",
        "            torch.save(model.state_dict(), os.path.join(MODEL_DIR, model_save_name))\n",
        "    gc.collect()\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "p0aFEVrTWrzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Function**: `valid_one_epoch`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Validates the model for one epoch. Optionally, can run without tqdm progress bar for evaluation purposes.\n",
        "\n",
        "**Parameters**:\n",
        "- `model` (nn.Module): The model to be validated.\n",
        "- `optimizer` (Optimizer): Optimizer for updating model weights (used for learning rate display).\n",
        "- `dataloader` (DataLoader): DataLoader object for validation data.\n",
        "- `device` (torch.device): Device to move data to (e.g., cuda, cpu).\n",
        "- `epoch` (int): Current validation epoch.\n",
        "- `evaluation` (bool, optional): Flag to disable tqdm progress bar.\n",
        "\n",
        "**Returns**:\n",
        "- `float`: The average loss for the epoch on validation data."
      ],
      "metadata": {
        "id": "Y5ufYGZiY1H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D15UF_pRjvGn"
      },
      "outputs": [],
      "source": [
        "def valid_one_epoch(model, optimizer, dataloader, device, epoch, evaluation=False):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    if not evaluation:\n",
        "        bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "    else:\n",
        "        bar = enumerate(dataloader)\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for step, data in bar:\n",
        "            x = data['x'].to(device)\n",
        "            y = data['y'].to(device)\n",
        "\n",
        "            batch_size = x.size(0)\n",
        "\n",
        "            logits, loss = model.forward(x, y)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            dataset_size += batch_size\n",
        "\n",
        "            epoch_loss = running_loss / dataset_size\n",
        "\n",
        "            if not evaluation:\n",
        "                bar.set_postfix(Epoch=epoch, Val_Loss=epoch_loss,\n",
        "                                LR=optimizer.param_groups[0]['lr'])\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GnTNAMWkvac"
      },
      "source": [
        "# **MidiDataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `MidiDataset`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Dataset class that loads MIDI files into tensors to create the dataset\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, df)`: Initializes the MidiDataset.\n",
        "  - `df` (DataFrame): DataFrame containing file names and other metadata.\n",
        "- `__len__(self)`: Returns the length of the dataset.\n",
        "- `__getitem__(self, idx)`: Gets the item at a specific index.\n",
        "  - `idx` (int): The global index to retrieve.\n",
        "\n",
        "**Returns for `__getitem__`**:\n",
        "- `dict`: A dictionary containing the following key-value pairs:\n",
        "  - `\"x\"`: The input tensor (shape `[SEQ_LEN, *]`).\n",
        "  - `\"y\"`: The target tensor (shape `[SEQ_LEN, *]`)."
      ],
      "metadata": {
        "id": "7UBqE04vZAtz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zSvL_mikz4M"
      },
      "outputs": [],
      "source": [
        "class MidiDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.indices = {}\n",
        "\n",
        "        globalIndex = 0\n",
        "        for fileIndex, row in df.iterrows():\n",
        "            fname = ENCODING_DIR + \"/\" + row[\"fname\"]\n",
        "            if not os.path.exists(fname):\n",
        "                continue\n",
        "            with open(fname, 'rb') as f:\n",
        "                nparray = np.load(f)\n",
        "            for arrayIndex in range(nparray.shape[0] - SEQ_LEN):\n",
        "                self.indices[globalIndex] = {\n",
        "                    'file': fname,\n",
        "                    'arrayIndex': arrayIndex\n",
        "                }\n",
        "                globalIndex += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.indices[idx]['file']\n",
        "        arrayIndex = self.indices[idx]['arrayIndex']\n",
        "        with open(fname, 'rb') as f:\n",
        "            nparray = np.load(f)\n",
        "        x = nparray[arrayIndex:arrayIndex+SEQ_LEN]\n",
        "        y = nparray[arrayIndex+1:arrayIndex+SEQ_LEN+1]\n",
        "\n",
        "        x = torch.tensor(x, dtype=torch.long)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "        return {\"x\": x, \"y\": y}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADRxeaQ9OUlm",
        "tags": []
      },
      "source": [
        "# **Transformer Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `AttentionHead`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Single head of the self-attention mechanism in Transformer model. Part of multi-head attention.\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, head_size, num_embed, block_size)`: Initializes the AttentionHead module.\n",
        "  - `head_size` (int): The dimension of each attention head.\n",
        "  - `num_embed` (int): The dimension of the input embeddings.\n",
        "  - `block_size` (int): The block size of the input sequence (maximum sequence length).\n",
        "- `forward(self, x)`: Performs the forward pass.\n",
        "  - `x` (Tensor): Input tensor of shape `(B, T, C)`.\n",
        "\n",
        "**Returns for `forward`**:\n",
        "- `Tensor`: The output tensor of shape `(B, T, C)`.\n"
      ],
      "metadata": {
        "id": "kWScpwIWZfCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    def __init__(self, head_size, num_embed, block_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.key = nn.Linear(num_embed, head_size, bias=False)\n",
        "        self.query = nn.Linear(num_embed, head_size, bias=False)\n",
        "        self.value = nn.Linear(num_embed, head_size, bias=False)\n",
        "        # tril is a lower triangular matrix. it is not a parameter\n",
        "        # of the model, so we assign it to the module using register_buffer\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        # compute attention scores\n",
        "        # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        # we need to transpose k to match q\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        # Tril matrix (lower triagular matrix) is used to mask\n",
        "        # future positions (setting them to -inf) so that the\n",
        "        # decoder \"learns\" to predict next words\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))  # (B,T,T)\n",
        "        wei = F.softmax(wei, dim=-1)  # (B,T,T)\n",
        "        # weighted aggregation of the values\n",
        "        v = self.value(x)\n",
        "        out = wei @ v  # (B,T,T) @ (B,T,C) ---> (B,T,C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Q5V_kpbuWzOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PoDFGiEOZ0nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `MultiHeadAttention`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Multi-head self-attention mechanism in Transformer model. Combines multiple `AttentionHead` modules in parallel and applies a linear projection.\n",
        "\n",
        "**Attributes**:\n",
        "- `heads`: A list of `AttentionHead` modules.\n",
        "- `proj`: Linear layer for projecting the concatenated attention head outputs back to the input dimension.\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, num_heads, head_size, num_embed, block_size)`: Initializes the MultiHeadAttention module.\n",
        "  - `num_heads` (int): The number of attention heads.\n",
        "  - `head_size` (int): The dimension of each attention head.\n",
        "  - `num_embed` (int): The dimension of the input embeddings.\n",
        "  - `block_size` (int): The block size of the input sequence (maximum sequence length).\n",
        "- `forward(self, x)`: Performs the forward pass.\n",
        "  - `x` (Tensor): Input tensor of shape `(B, T, C)`.\n",
        "\n",
        "**Returns for `forward`**:\n",
        "- `Tensor`: The output tensor of shape `(B, T, C)`."
      ],
      "metadata": {
        "id": "TmqMGHyYZ4io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size, num_embed, block_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [\n",
        "                AttentionHead(\n",
        "                    head_size=head_size,\n",
        "                    num_embed=num_embed,\n",
        "                    block_size=block_size,\n",
        "                )\n",
        "                for _ in range(num_heads)\n",
        "            ]\n",
        "        )\n",
        "        self.proj = nn.Linear(num_embed, num_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # output of the self-attention\n",
        "\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "         # (B, T, num_heads * head_size)\n",
        "        # apply the linear projection layer\n",
        "        out = self.proj(out)\n",
        "        # (B, T, num_embed)\n",
        "        return out"
      ],
      "metadata": {
        "id": "EZMwx6_zW2KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `FeedForward`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Feed-forward neural network layer. Linear transformation followed by a ReLU activation then additional linear layer.\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, num_embed)`: Initializes the FeedForward module.\n",
        "  - `num_embed` (int): The dimension of the input embeddings.\n",
        "- `forward(self, x)`: Performs the forward pass.\n",
        "  - `x` (Tensor): Input tensor of shape `(B, T, C)`.\n",
        "\n",
        "**Returns for `forward`**:\n",
        "- `Tensor`: The output tensor of shape `(B, T, C)`."
      ],
      "metadata": {
        "id": "x9trQDwiaNT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, num_embed):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(num_embed, 4 * num_embed),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(4 * num_embed, num_embed),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "pTu6xs48W4Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `TransformerBlock`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Single block in a Transformer model.\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, num_heads, block_size, num_embed)`: Initializes the TransformerBlock.\n",
        "  - `num_heads` (int): The number of attention heads.\n",
        "  - `block_size` (int): The block size of the input sequence.\n",
        "  - `num_embed` (int): The dimension of the input embeddings.\n",
        "- `forward(self, x)`: Performs the forward pass.\n",
        "  - `x` (Tensor): Input tensor of shape `(B, T, C)`.\n"
      ],
      "metadata": {
        "id": "9NC0ZbKpakDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, block_size, num_embed):\n",
        "        super().__init__()\n",
        "        head_size = num_embed // num_heads\n",
        "        self.sa = MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            head_size=head_size,\n",
        "            num_embed=num_embed,\n",
        "            block_size=block_size,\n",
        "        )\n",
        "        self.ffwd = FeedForward(num_embed=num_embed)\n",
        "        # add the layer normalization\n",
        "        self.ln1 = nn.LayerNorm(num_embed)\n",
        "        self.ln2 = nn.LayerNorm(num_embed)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "H8Pf0CV2W6HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Class**: `Transformer`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Comprises multiple `TransformerBlock` units, token and position embeddings, and a linear output layer for language modeling.\n",
        "\n",
        "**Methods**:\n",
        "- `__init__(self, **kwargs)`: Initializes the Transformer model with optional keyword arguments.\n",
        "- `forward(self, idx, targets=None)`: Performs the forward pass and optionally computes the loss.\n",
        "  - `idx` (Tensor): Input token indices. Shape `(B, T)`.\n",
        "  - `targets` (Tensor, optional): Ground truth token indices. Used for loss computation.\n",
        "- `generate(self, idx, max_new_tokens, block_size)`: Generates a sequence given an input context.\n",
        "  - `idx` (Tensor): Input token indices. Shape `(B, T)`.\n",
        "  - `max_new_tokens` (int): Maximum number of new tokens to generate.\n",
        "  - `block_size` (int): Length of the block to consider for generation.\n",
        "\n",
        "**Returns for `forward`**:\n",
        "- `Tuple`: Consists of `logits` (Tensor) and `loss` (float or None).\n",
        "\n",
        "**Returns for `generate`**:\n",
        "- `Tensor`: Generated sequence of tokens."
      ],
      "metadata": {
        "id": "pfSdQfS8bItV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P-C9eWRj6nQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = kwargs.get(\"vocab_size\", 100)\n",
        "        self.num_embed = kwargs.get(\"num_embed\", 32)\n",
        "        self.block_size = kwargs.get(\"block_size\", 8)\n",
        "        self.num_heads = kwargs.get(\"num_heads\", 4)\n",
        "        self.num_layers = kwargs.get(\"num_layers\", 4)\n",
        "        # each token reads the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(self.vocab_size, self.num_embed)\n",
        "        # each position from 0 to block_size-1 will get its embedding\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, self.num_embed)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[\n",
        "                TransformerBlock(\n",
        "                    num_heads=self.num_heads,\n",
        "                    block_size=self.block_size,\n",
        "                    num_embed=self.num_embed,\n",
        "                )\n",
        "                for _ in range(self.num_layers)\n",
        "            ]\n",
        "        )\n",
        "        # we add the layer norm before the Linear layer\n",
        "        self.ln_f = nn.LayerNorm(self.num_embed)\n",
        "        self.lm_head = nn.Linear(self.num_embed, self.vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are (B,T) tensor of integers\n",
        "        # the token_emb is (B, T, C), C = NUM_EMBED\n",
        "        token_emb = self.token_embedding_table(idx)\n",
        "        # (T, C)\n",
        "        posit_emb = self.position_embedding_table(torch.arange(T, device=DEVICE))\n",
        "\n",
        "        x = token_emb + posit_emb\n",
        "        # apply one head of self-attention\n",
        "        x = self.blocks(x)\n",
        "        # (B, T, vocab_size)\n",
        "        logits = self.lm_head(x)\n",
        "        # compute the loss\n",
        "        if targets != None:\n",
        "\n",
        "            B, T, C = logits.shape\n",
        "            logits = torch.reshape(logits, (B * T, C))\n",
        "            targets = torch.reshape(targets, (B * T,))\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        else:\n",
        "            loss = None\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx: torch.Tensor, max_new_tokens: int, block_size: int):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop the context too the  last block_size tokens\n",
        "            # because tokens don't communicate between blocks\n",
        "            idx_crop = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(idx_crop)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution with probabilities probs\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdGU3t3Skjp2"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Function**: `save_training_info`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Saves the training and validation loss information along with hyperparameters and model details into a text file."
      ],
      "metadata": {
        "id": "9I-IpABjbwIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_info(train_losses, val_losses, text_file_name, learning_rate, dropout):\n",
        "    text_file_name = text_file_name + \".txt\"\n",
        "    with open(f'data_plots/{text_file_name}', 'w') as f:\n",
        "        f.write(\"Model Information:\\n\")\n",
        "        f.write(\"===================\\n\")\n",
        "        f.write(f\"File Name: {text_file_name}\\n\")\n",
        "        f.write(f\"Batch Size: {BATCH_SIZE}\\n\")\n",
        "        f.write(f\"Block Size: {SEQ_LEN}\\n\")\n",
        "        f.write(f\"Max Iterations: {0}\\n\")\n",
        "        f.write(f\"Learning Rate: {LR}\\n\")\n",
        "        f.write(f\"Device: {DEVICE}\\n\")\n",
        "        f.write(f\"Embedding Dimension: {EMBED_DIM}\\n\")\n",
        "        f.write(f\"Number of Attention Heads: {TRANSFORMER_HEADS}\\n\")\n",
        "        f.write(f\"Number of Layers: {TRANSFORMER_LAYERS}\\n\")\n",
        "        f.write(f\"Dropout Rate: {dropout}\\n\")\n",
        "        f.write(\"\\nPlot Information:\\n\")\n",
        "        f.write(\"==================\\n\")\n",
        "        for iter_num, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses)):\n",
        "            f.write(f\"Iteration {iter_num * EVAL_INTERVAL}: Train Loss = {train_loss:.4f}, Validation Loss = {val_loss:.4f}\\n\")"
      ],
      "metadata": {
        "id": "vJHI70Lobm17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Function**: `plot_and_save`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Plots and saves the real-time loss values during the training and validation processes. Also displays other relevant information like current iteration, hyperparameters, and architecture details.\n"
      ],
      "metadata": {
        "id": "IjLkxLcRb5Xq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDCrQWU2uvK6"
      },
      "outputs": [],
      "source": [
        "def plot_and_save(i, train_losses, val_losses, data_file_name, parameters, n_embd, n_head, n_layer):\n",
        "    # Clear previous plots and information\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    display(HTML(f\"<b>Iteration {i}</b>:<br>Train Loss: {train_losses[-1]:.4f}<br>Validation Loss: {val_losses[-1]:.4f}<br>Parameters: {parameters}<br>n_embd: {n_embd}<br>n_layer: {n_head}<br>n_layer: {n_layer}\"))\n",
        "\n",
        "    # Define the figure and axis\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.cla()  # Clear the current axes\n",
        "\n",
        "    # Plot the losses with adjusted styles\n",
        "    plt.plot(train_losses, label=\"Training Loss\", color='blue', linewidth=2)\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", color='red', linestyle='--', linewidth=2)\n",
        "\n",
        "    # Set labels, title, legend, and grid\n",
        "    plt.xlabel(\"Evaluation Interval\", fontsize=14)\n",
        "    plt.ylabel(\"Loss\", fontsize=14)\n",
        "    plt.title(\"Real-time Loss Plot\", fontsize=16)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "    # Adjust the layout\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    if not os.path.exists('data_plots'):\n",
        "        os.mkdir('data_plots')\n",
        "    plt.savefig(f'data_plots/{data_file_name}.png')\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "    # Close the figure\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az_wkNUMzjt0"
      },
      "source": [
        "---\n",
        "## **Function**: `train`\n",
        "---\n",
        "\n",
        "**Description**:\n",
        "Trains Transformer model on MIDI data. Sets up logging, loads data, pre-processes it, and carries out the training and validation steps across multiple epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BszQqzTlklET"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    NOW = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M')\n",
        "    # Prepping directories\n",
        "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "    os.makedirs(LOG_DIR, exist_ok=True)\n",
        "    logging.basicConfig(\n",
        "        level=logging.DEBUG,  # Set the logging level to DEBUG (adjust as needed)\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',  # Define log message format\n",
        "        filename=LOG_DIR+'/app_{}.log'.format(SUFFIX),  # Specify log file name\n",
        "        filemode='w'  # Set file mode to write (overwrite if file exists)\n",
        "    )\n",
        "    logging.info(\"loading files...\")\n",
        "    print(\"loading files...\")\n",
        "\n",
        "    with open(ENCODING_DIR+\"/tokenizer.json\", 'rb') as file:\n",
        "        tokenizer = json.load(file)\n",
        "\n",
        "    df = pd.read_csv(ENCODING_DIR+'/df.csv')\n",
        "    logging.info(\"dataset size: {}\".format(df.shape[0]))\n",
        "    print(\"dataset size: {}\".format(df.shape[0]))\n",
        "\n",
        "    # Data preparation\n",
        "    train_df = df.loc[:int(len(df)*TRAIN_TEST_RATIO), :]\n",
        "    val_df = df.loc[int(len(df)*TRAIN_TEST_RATIO):, :]\n",
        "\n",
        "    # Make sure preload directory exists\n",
        "    if not os.path.exists(\"./preload\"):\n",
        "        os.mkdir(\"./preload\")\n",
        "\n",
        "    # Check if train pickle file exists\n",
        "    pickle_path = \"./preload/train_df.pkl\"\n",
        "    if os.path.exists(pickle_path):\n",
        "        print('Preloading Dataset Indices')\n",
        "        with open(pickle_path, 'rb') as f:\n",
        "            train_df = pickle.load(f)\n",
        "        return\n",
        "    else:\n",
        "        train_data = MidiDataset(train_df)\n",
        "        with open(pickle_path, 'wb') as f:\n",
        "            pickle.dump(train_data, f)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Check if train pickle file exists\n",
        "    pickle_path = \"./preload/val_df.pkl\"\n",
        "    if os.path.exists(pickle_path):\n",
        "        print('Preloading Dataset Indices')\n",
        "        with open(pickle_path, 'rb') as f:\n",
        "            eval_data = pickle.load(f)\n",
        "        return\n",
        "    else:\n",
        "        eval_data = MidiDataset(val_df)\n",
        "        with open(pickle_path, 'wb') as f:\n",
        "            pickle.dump(eval_data, f)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    eval_dataloader = torch.utils.data.DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = Transformer(vocab_size=VOCAB_SIZE,\n",
        "                        num_embed=EMBED_DIM,\n",
        "                        block_size=SEQ_LEN,\n",
        "                        num_heads=TRANSFORMER_HEADS,\n",
        "                        num_layers=TRANSFORMER_LAYERS)\n",
        "\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "    if num_gpus > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    param_optimizer = model.parameters()\n",
        "    optimizer = torch.optim.AdamW(param_optimizer, lr=LR)\n",
        "    parameters = sum(p.numel() for p in model.parameters())/1e6\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_loss = np.inf\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        gc.collect()\n",
        "\n",
        "        train_loss = train_one_epoch(model, optimizer, train_dataloader, DEVICE, epoch, parameters, eval_interval=EVAL_INTERVAL, eval_dataloader=eval_dataloader)\n",
        "        history[\"TrainLoss\"].append(train_loss)\n",
        "\n",
        "        val_loss = valid_one_epoch(model, optimizer, eval_dataloader, DEVICE, epoch)\n",
        "        history[\"ValLoss\"].append(val_loss)\n",
        "\n",
        "        logging.debug(\"Epoch: {} TL: {} VL: {}\".format(epoch, train_loss, val_loss))\n",
        "        if val_loss < best_epoch_loss:\n",
        "            logging.debug(f\"Validation Loss Improved ({best_epoch_loss} ---> {val_loss})\")\n",
        "            best_epoch_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            PATH = f\"{FILE_NAME}.pt\"\n",
        "            torch.save(model.state_dict(), os.path.join(MODEL_DIR, PATH))\n",
        "            logging.debug(\"Model Saved\")\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "\n",
        "    logging.debug('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    logging.debug(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n",
        "\n",
        "    PATH = f\"lst_{FILE_NAME}.pt\"\n",
        "    torch.save(model.state_dict(), os.path.join(MODEL_DIR, PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJPNP_9dlUpq"
      },
      "source": [
        "\n",
        "# **Train Bench**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7hG4JPulkKF"
      },
      "source": [
        "---\n",
        "## **Config**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVadC3Erln0H"
      },
      "outputs": [],
      "source": [
        "NOW = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M')\n",
        "DEVICE = 'cuda'\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 7000\n",
        "SEQ_LEN = 128\n",
        "VOCAB_SIZE = len(REMIPlus().vocab)\n",
        "LOG_DIR = 'output/logs'\n",
        "TRAIN_TEST_RATIO = 0.9\n",
        "\n",
        "EMBED_DIM = 768\n",
        "TRANSFORMER_HEADS = 8\n",
        "TRANSFORMER_LAYERS = 1\n",
        "LR = 9e-6\n",
        "SUFFIX=\"gameboy002\"\n",
        "\n",
        "EVAL_INTERVAL = 100\n",
        "MODEL_DIR = 'output/model_{}'.format(SUFFIX)\n",
        "ENCODING_DIR = './encoding/gameboy_midi_encode'\n",
        "\n",
        "FILE_PREFIX = 'Gameboy002_'\n",
        "FILE_NAME = FILE_PREFIX + NOW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNgcz5fWo9PK"
      },
      "source": [
        "---\n",
        "## **Train Model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rXNNeU5clYqp",
        "outputId": "93421907-78d0-4335-85d2-fd1d7dc2c82b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<b>Iteration 400</b>:<br>Train Loss: 0.0195<br>Validation Loss: 0.0195<br>Parameters: 8.056695<br>n_embd: 768<br>n_layer: 8<br>n_layer: 1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 405/1957075 [21:09<1703:49:51,  3.13s/it, Epoch=1, LR=9e-6, Train_Loss=0.0195]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-45fda03b7372>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVAL_INTERVAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TrainLoss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-4c7c82d394fd>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, dataloader, device, epoch, parameters, eval_interval, eval_dataloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/lib/python3/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Bench**"
      ],
      "metadata": {
        "id": "T-hYmPpNdXQo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVQzxzYao5BB"
      },
      "source": [
        "---\n",
        "## **Load Model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT1MnP9HovFg"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    # Load state dictionary from disk\n",
        "    state_dict = torch.load(model_path)\n",
        "\n",
        "    # Create a new state dictionary without the 'module.' prefix\n",
        "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
        "\n",
        "    model = Transformer(\n",
        "        vocab_size = VOCAB_SIZE,\n",
        "        num_embed = EMBED_DIM,\n",
        "        block_size = SEQ_LEN,\n",
        "        num_heads = TRANSFORMER_HEADS,\n",
        "        num_layers = TRANSFORMER_LAYERS)\n",
        "\n",
        "    model.load_state_dict(new_state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Create Songs**\n",
        "---"
      ],
      "metadata": {
        "id": "m-zyzaDoc4nu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOvyDSqf1KHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6522fc45-a63c-445d-84ee-f386c73b781b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test0 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test1 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test2 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test3 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test4 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test5 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test6 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test7 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test8 has been written.\n",
            "tensor([[126, 213, 312,  63, 117, 128, 284,  22, 124, 127, 296,  22, 124, 127,\n",
            "         238,  50, 124, 132, 217, 312,  62, 117, 128, 284,  22, 124, 127, 296,\n",
            "          22, 124, 132, 238,  46, 124, 132,   4, 374, 189, 312,  60, 117, 128,\n",
            "         238,  54, 124, 132, 193, 312,  63, 117, 128, 284,  29, 123, 128, 296,\n",
            "          29, 124, 128, 238,  46, 124, 131, 197]], device='cuda:0')\n",
            "Song gameboy004_test9 has been written.\n"
          ]
        }
      ],
      "source": [
        "song_prefix = 'gameboy001_test'\n",
        "model_name = 'Gameboy002_2023-09-19_04_18_e_8_s_400'\n",
        "context_length = 64\n",
        "song_length = 1024\n",
        "block_size = 64\n",
        "\n",
        "test_set = 0\n",
        "\n",
        "for i in range(10):\n",
        "    model_path = f'output/{model_name}.pt'\n",
        "    torch.manual_seed(random.randint(1, 1_000_000))\n",
        "    model = load_model(model_path).to(DEVICE)\n",
        "\n",
        "    with open('encoding/0_newbarktown.npy', 'rb') as f:\n",
        "        initial_idx = np.load(f)\n",
        "\n",
        "    length = context_length\n",
        "    initial_idx = torch.tensor([initial_idx.tolist()[length:length * 2]]).to(DEVICE)\n",
        "\n",
        "    generated_sequence = model.generate(initial_idx, max_new_tokens=song_length, block_size=block_size).tolist()\n",
        "\n",
        "    song_name = song_prefix + str(i * test_set)\n",
        "\n",
        "    if not os.path.exists('songs'):\n",
        "        os.makedirs('songs')\n",
        "\n",
        "    tokenizer = REMIPlus()\n",
        "    midi = tokenizer.tokens_to_midi(generated_sequence[0][length:])\n",
        "    midi.dump(f'./songs/{song_name}.midi')\n",
        "    print(f'Song {song_name} has been written.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}